{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rhyme_corpus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 라임 기반의 작사 모델 - 라임 스코어"
      ],
      "metadata": {
        "id": "wTBvGcuVjaqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용한 라이브러리와 오픈소스\n",
        "\n",
        "1. hgtk : https://github.com/bluedisk/hangul-toolkit\n",
        "2. googletrans : https://github.com/ssut/py-googletrans\n",
        "3. request : https://github.com/psf/requests\n",
        "4. 엑셀 오픈 모듈 openpyxl : https://openpyxl.readthedocs.io/en/stable/\n",
        "5. 데이터 프레임 라이브러리 pandas : https://pandas.pydata.org/\n",
        "6. 영어 => 한글발음 : \"https://transliterator.herokuapp.com/\"\n",
        "7. 한국어 word2vec : https://github.com/Kyubyong/wordvectors"
      ],
      "metadata": {
        "id": "hG3SkxFeRMdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K5oAF_2yXuUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf1d0d0-36ee-46b5-8ece-0f58def898a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#환경이 google colab인 경우\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount= True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "8qq3y2NrKqcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b603d1a-f9d6-4c04-8b8b-bfdc708870d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans==4.0.0rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "Collecting hgtk==0.1.3\n",
            "  Downloading hgtk-0.1.3.tar.gz (6.2 kB)\n",
            "Collecting transformers==4.19.2\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 41.4 MB/s \n",
            "\u001b[?25hCollecting fastai==2.2.5\n",
            "  Downloading fastai-2.2.5-py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 60.6 MB/s \n",
            "\u001b[?25hCollecting kss==3.4.2\n",
            "  Downloading kss-3.4.2.tar.gz (42.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.4 MB 73.1 MB/s \n",
            "\u001b[?25hCollecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 66.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2->-r requirements.txt (line 3)) (3.7.0)\n",
            "Collecting torchvision<0.9,>=0.8\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (7.1.2)\n",
            "Collecting fastcore<1.4,>=1.3.8\n",
            "  Downloading fastcore-1.3.29-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting torch<1.8,>=1.7.0\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (1.3.5)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (21.1.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai==2.2.5->-r requirements.txt (line 4)) (1.0.2)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from kss==3.4.2->-r requirements.txt (line 5)) (8.13.0)\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1->-r requirements.txt (line 1)) (2022.5.18.1)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 44.5 MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1->-r requirements.txt (line 1)) (3.0.4)\n",
            "Collecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.2->-r requirements.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.2->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.2->-r requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.2.5->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.2.5->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==2.2.5->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai==2.2.5->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==2.2.5->-r requirements.txt (line 4)) (2022.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.2->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.2.5->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai==2.2.5->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (0.9.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (2.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai==2.2.5->-r requirements.txt (line 4)) (3.0.6)\n",
            "Building wheels for collected packages: googletrans, hgtk, kss, emoji\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17416 sha256=4d0e07c09d007303568e48be4d60a62c1d29ae5e7086c475c261ce90bbd453bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/34/00/4fe71786ea6d12314b29037620c36d857e5d104ac2748bf82a\n",
            "  Building wheel for hgtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6689 sha256=8f3f4eb963669fe17c242e2d4ffdb47559c9ce96b16a51ef5353bd18a00eef95\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/e9/bc/524beb5222b11aa439a23a07be5bd8a559d266153103c37979\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-3.4.2-py3-none-any.whl size=42448069 sha256=18c695155fd6a5efe3def9c8b0086b43433c0f7c5ad61780271398e558309f5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/22/aa/6399b60516a067ec97fa6599fb2d472aeb25e3f9ee6dae3224\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=1cdc66600072da4593e142f3e47837c220a8372443033aad24bc9d0287be4ace\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built googletrans hgtk kss emoji\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, torch, rfc3986, pyyaml, httpcore, hstspreload, torchvision, tokenizers, huggingface-hub, httpx, fastcore, emoji, transformers, kss, hgtk, googletrans, fastai\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0+cu113\n",
            "    Uninstalling torchvision-0.12.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.12.0+cu113\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed emoji-1.7.0 fastai-2.2.5 fastcore-1.3.29 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hgtk-0.1.3 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 huggingface-hub-0.7.0 hyperframe-5.2.0 kss-3.4.2 pyyaml-6.0 rfc3986-1.5.0 sniffio-1.2.0 tokenizers-0.12.1 torch-1.7.1 torchvision-0.8.2 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#필요한 라이브러리 로드\n",
        "\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import re\n",
        "import openpyxl\n",
        "import requests \n",
        "import googletrans\n",
        "import hgtk\n",
        "import gensim\n",
        "from sys import stdout"
      ],
      "metadata": {
        "id": "UtpPO_5tgSc2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라임 스코어링에 사용할 단어 로드\n",
        "#( 자주 사용되는 기본 단어 목록 + 사용할 가사 데이터)\n",
        "\n",
        "#lyrics\n",
        "#사용할 데이터 경로 지정\n",
        "\n",
        "#=============================================================================\n",
        "base = \"/gdrive/My Drive/Colab Notebooks/corpus_data/corpus.xlsx\"\n",
        "lyrics = \"/gdrive/My Drive/Colab Notebooks/corpus_data/hiphop.txt\"\n",
        "\n",
        "lyrics_xlsx_list = [\"9000D\",\"9000B\",\"0110D\",\"0110B\",\"1119B\",\"1119D\"]\n",
        "#=============================================================================\n",
        "\n",
        "base_df = pd.read_excel(base, engine='openpyxl')\n",
        "\n",
        "#기본단어 , 가사중 kor , 가사중 eng\n",
        "base_word = []\n",
        "lyric_word_kor = []\n",
        "lyric_word_eng = []\n",
        "\n",
        "for i in base_df.itertuples():\n",
        "   x = re.sub('[^A-Za-z가-힣]', '', i.단어)\n",
        "   base_word.append(x)\n",
        "\n",
        "lydata = open(lyrics, \"r\", encoding='euc-kr').read().splitlines()\n",
        "for i in lydata:\n",
        "  split_word = list(i.split(\" \"))\n",
        "  for word in split_word:\n",
        "    if word.upper() != word.lower():\n",
        "      word = re.sub('[^A-Za-z]', '', word)\n",
        "      lyric_word_eng.append(word)\n",
        "    else:\n",
        "      word = re.sub('[^가-힣]', '', word)\n",
        "      lyric_word_kor.append(word)\n",
        "\n",
        "lyric_word_kor = list(set(lyric_word_kor))\n",
        "lyric_word_eng = list(set(lyric_word_eng))\n",
        "\n",
        "print(len(lyric_word_kor))\n",
        "print(len(lyric_word_eng))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_Q60ojZitX6",
        "outputId": "e03d30f3-f4dc-46a5-8760-4395ad23cc88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4896\n",
            "898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#=============================================================================\n",
        "\n",
        "lyrics_xlsx_list = [\"9000D\",\"9000B\",\"0110D\",\"0110B\",\"1119B\",\"1119D\"]\n",
        "base_xl = \"/gdrive/My Drive/Colab Notebooks/corpus_data/\"\n",
        "\n",
        "#=============================================================================\n",
        "\n",
        "lines = \"\"\n",
        "for k in lyrics_xlsx_list:\n",
        "  base_df_ly = pd.read_excel(base_xl+k+\".xlsx\", engine='openpyxl')\n",
        "\n",
        "  for i in base_df_ly.itertuples():\n",
        "    ly_line = i.lyrics\n",
        "    for word in ly_line.split(\" \"):\n",
        "      if word.upper() != word.lower():\n",
        "        word = re.sub('[^A-Za-z]', '', word)\n",
        "        lyric_word_eng.append(word)\n",
        "      else:\n",
        "        word = re.sub('[^가-힣]', '', word)\n",
        "        lyric_word_kor.append(word)\n",
        "\n",
        "lyric_word_kor = list(set(lyric_word_kor))\n",
        "lyric_word_eng = list(set(lyric_word_eng))\n",
        "\n",
        "print(len(lyric_word_kor))\n",
        "print(len(lyric_word_eng))\n",
        "lyric_word_eng_to_kor = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrsMQuUbW_mf",
        "outputId": "051ef382-0a0f-4b73-9c1a-42d7d5d0c0ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57769\n",
            "6440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#영어를 한글 발음으로 변환해주는 사이트를 이용\n",
        "#영문 단어들에 대한 라임을 고려하기 위해 한글발음으로 변환\n",
        "\n",
        "#영문단어를 사용하지 않는다면 실행 X\n",
        "\n",
        "lyric_word_eng_to_kor = {}\n",
        "translator = googletrans.Translator()\n",
        "\n",
        "url = \"https://transliterator.herokuapp.com/\"\n",
        "sess = requests.Session()\n",
        "\n",
        "all = len(lyric_word_eng)\n",
        "idx = 0\n",
        "\n",
        "for i in lyric_word_eng:\n",
        "  payload = {'input': i}\n",
        "  res = sess.post(url, data = payload)\n",
        "  change_kor = res.json()['output'].replace('?',' ')\n",
        "  \n",
        "  result = translator.translate(i, dest='ko')\n",
        "\n",
        "  lyric_word_eng_to_kor[i] = [change_kor,result.text]\n",
        "  \n",
        "  progress = 100*(idx+1)/all\n",
        "  stdout.write(\"\\r ===== %d%% completed =====\" % progress)\n",
        "  stdout.flush()\n",
        "  idx += 1\n",
        "stdout.write(\"\\n\")\n",
        "\n",
        "#딕셔너리에 영어단어 : [발음 , 의미] 로 mapping\n",
        "print(lyric_word_eng_to_kor)\n",
        "\n"
      ],
      "metadata": {
        "id": "YE3gRuLpy7-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#두 단어 사이의 hit을 매기는 함수 \n",
        "#라임의 경우 모음에 치중한 경우가 많아 모음에 hit score를 더줌\n",
        "#모음이 같은 경우 : +2 / 자음이 같은 경우 +1\n",
        "\n",
        "def rhyme_score(word1, word2):\n",
        "  if len(word1) > len(word2):\n",
        "    swap = word1\n",
        "    word1 = word2\n",
        "    word2 = swap\n",
        "\n",
        "  w1_slice = []\n",
        "  w2_every = []\n",
        "  for i in word1:\n",
        "    a = hgtk.letter.decompose(i)\n",
        "    w1_slice.append(a)\n",
        "\n",
        "  for i in range(0,len(word2)-len(word1)+1):\n",
        "    w2 = word2[i:i+len(word1)]\n",
        "    w2_slice = []\n",
        "    for k in w2:\n",
        "      a = hgtk.letter.decompose(k)\n",
        "      w2_slice.append(a)\n",
        "    w2_every.append(w2_slice)\n",
        "\n",
        "  max_hit = 0\n",
        "  for idx in w2_every:\n",
        "    hit = 0\n",
        "    for i in range(len(w1_slice)):\n",
        "      for k in range(3):\n",
        "        if w1_slice[i][k] != \"\" and idx[i][k] != \"\":\n",
        "          if w1_slice[i][k] == idx[i][k]:\n",
        "            if k == 1:\n",
        "              hit += 2\n",
        "            else:\n",
        "              hit += 1\n",
        "    if hit > max_hit:\n",
        "      max_hit = hit\n",
        "\n",
        "  return max_hit\n"
      ],
      "metadata": {
        "id": "QQ0Vp1GW07iu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base 단어에 대한 score 예시\n",
        "\n",
        "def score_rank(key_word,max_hit_times,min_hit_times):\n",
        "  base_score = [] #기본 단어 스코어\n",
        "  lyric_score = [] #가사 단어 스코어\n",
        "  lyric_eng_score = [] #영단어 스코어\n",
        "\n",
        "  for i in base_word:\n",
        "    base_score.append([i,rhyme_score(key_word,i)])\n",
        "\n",
        "  for i in lyric_word_kor:\n",
        "    lyric_score.append([i,rhyme_score(key_word,i)])\n",
        "\n",
        "  for i in lyric_word_eng_to_kor.keys():\n",
        "    kors = lyric_word_eng_to_kor[i]\n",
        "    lyric_eng_score.append([i,rhyme_score(key_word,kors[0])])\n",
        "\n",
        "  base_score = [i for i in base_score if max_hit_times >= i[1] >= min_hit_times]\n",
        "  lyric_score = [i for i in lyric_score if max_hit_times >= i[1] >= min_hit_times]\n",
        "  lyric_eng_score = [i for i in lyric_eng_score if max_hit_times >= i[1] >= min_hit_times]\n",
        "\n",
        "  base_score.sort(key=lambda x : x[1],reverse=True)\n",
        "  lyric_score.sort(key=lambda x : x[1],reverse=True)\n",
        "  lyric_eng_score.sort(key=lambda x : x[1],reverse=True)\n",
        "\n",
        "  return base_score , lyric_score , lyric_eng_score"
      ],
      "metadata": {
        "id": "Z5z4JCtoHt0Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=============================================================================\n",
        "\n",
        "word2vec_model = gensim.models.Word2Vec.load(\"/gdrive/My Drive/Colab Notebooks/corpus_data/ko/ko.bin\")\n",
        "\n",
        "#============================================================================="
      ],
      "metadata": {
        "id": "Z-qg1l76Hk56"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similar(word_1 , word_2):\n",
        "  try:\n",
        "\t  return (word2vec_model.wv.similarity(word_1,word_2))\n",
        "  except:\n",
        "\t  return -1"
      ],
      "metadata": {
        "id": "vFXBFhe0MxOK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sim_after_rhyme(key_word,max_hit_times,min_hit_times,min_level = 0):\n",
        "  a,b,c = score_rank(key_word,max_hit_times,min_hit_times)\n",
        "\n",
        "  base_sim = []\n",
        "\n",
        "  for i in a:\n",
        "    level = similar(key_word,i[0])\n",
        "    if level > min_level:\n",
        "      base_sim.append([i[0],i[1],level])\n",
        "\n",
        "  for i in b:\n",
        "    level = similar(key_word,i[0])\n",
        "    if level > min_level:\n",
        "      base_sim.append([i[0],i[1],level])\n",
        "\n",
        "  for i in c:\n",
        "    op = lyric_word_eng_to_kor[i[0]]\n",
        "    level = similar(key_word,op[1])\n",
        "    if level > min_level:\n",
        "      base_sim.append([i[0],i[1],level])\n",
        "  \n",
        "  base_sim.sort(key=lambda x : x[2],reverse=True)\n",
        "\n",
        "  return base_sim "
      ],
      "metadata": {
        "id": "kjpeDMaBO1Fy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 작사 모델 - KoGPT2\n"
      ],
      "metadata": {
        "id": "eHEEWXM4rISB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용 라이브러리와 오픈소스\n",
        "\n",
        "1. 파이토치 : https://pytorch.kr/\n",
        "2. koGPT2 : https://github.com/SKT-AI/KoGPT2\n",
        "3. fastai : https://github.com/fastai/fastai\n",
        "4. transformers : https://github.com/huggingface/transformers\n",
        "5. 한국어 글 문장 분리기 kss : https://github.com/hyunwoongko/kss"
      ],
      "metadata": {
        "id": "znczc0khrT5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast\n",
        "from fastai.text.all import *\n",
        "import fastai\n",
        "import re\n",
        "from transformers import GPT2LMHeadModel\n",
        "import kss"
      ],
      "metadata": {
        "id": "Anr6WTRpraMR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRQ7aGVi4Wug",
        "outputId": "9dd1ec4c-6700-49c6-c97a-0aa6930ce858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 26 18:20:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    28W /  70W |   4502MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 새로 Fine Tuning 하기\n",
        "모델이 이미 있다면 , 스킵"
      ],
      "metadata": {
        "id": "5wV3-FWEPf3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KoGPT2 tokenizer,모델 불러오기\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>') \n",
        "model = AutoModelWithLMHead.from_pretrained(\"skt/kogpt2-base-v2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kLQuZIZrby_",
        "outputId": "7a4db456-75d1-4eae-a204-d01a16dd1365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model input output tokenizer\n",
        "class TransformersTokenizer(Transform):\n",
        "   def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
        "   def encodes(self, x): \n",
        "       toks = self.tokenizer.tokenize(x)\n",
        "       return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
        "   def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))\n"
      ],
      "metadata": {
        "id": "U8hk6kp3gXTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 tokenization\n",
        "#base_xl : 가사 데이터 위치 / lyrics_xlsx_list : 파일이름 리스트\n",
        "#xlsx 파일 오픈 , txt나 타 파일의 경우 , 또 다른 xlsx 파일의 경우 \n",
        "#코드 수정 필요\n",
        "\n",
        "#단어를 한 단어씩 띄어 lines에 모두 넣어주면 됨\n",
        "#lines= lines + \" \".join(ly_line.split())\n",
        "\n",
        "lyrics_xlsx_list = [\"9000D\",\"9000B\",\"0110D\",\"0110B\",\"1119B\",\"1119D\"]\n",
        "base_xl = \"/gdrive/My Drive/Colab Notebooks/corpus_data/\"\n",
        "\n",
        "lines = \"\"\n",
        "for k in lyrics_xlsx_list:\n",
        "  base_df_ly = pd.read_excel(base_xl+k+\".xlsx\", engine='openpyxl')\n",
        "\n",
        "  for i in base_df_ly.itertuples():\n",
        "    ly_line = i.lyrics\n",
        "    lines= lines + \" \".join(ly_line.split())\n",
        "  print(k)\n",
        "\n",
        "print(len(lines))\n",
        "\n",
        "#split data\n",
        "train=lines[:int(len(lines)*0.9)]\n",
        "test=lines[int(len(lines)*0.9):]\n",
        "splits = [[0],[1]]\n",
        "\n",
        "#init dataloader\n",
        "tls = TfmdLists([train,test], TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
        "batch,seq_len = 8,256\n",
        "dls = tls.dataloaders(bs=batch, seq_len=seq_len)\n",
        "\n",
        "#약 13분 소요"
      ],
      "metadata": {
        "id": "RkQe4P_EtyiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 구성 후 fine_tuning 진행\n",
        "#gpt2 ouput is tuple, we need just one val\n",
        "class DropOutput(Callback):\n",
        "  def after_pred(self): self.learn.pred = self.pred[0]\n",
        "      \n",
        "      \n",
        "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()\n",
        "lr=learn.lr_find()\n",
        "print(lr)\n",
        "learn.fine_tune(6)\n",
        "\n",
        "#21분 소요"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "ogNvoD-2uHx6",
        "outputId": "8fee9a4b-3682-429b-c405-5c35877c6494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SuggestedLRs(lr_min=0.010000000149011612, lr_steep=0.0831763744354248)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.914434</td>\n",
              "      <td>5.016362</td>\n",
              "      <td>150.861496</td>\n",
              "      <td>03:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.824803</td>\n",
              "      <td>4.103664</td>\n",
              "      <td>60.561802</td>\n",
              "      <td>03:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.577798</td>\n",
              "      <td>3.893196</td>\n",
              "      <td>49.067436</td>\n",
              "      <td>03:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.138651</td>\n",
              "      <td>3.775068</td>\n",
              "      <td>43.600452</td>\n",
              "      <td>03:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.661606</td>\n",
              "      <td>3.767436</td>\n",
              "      <td>43.268970</td>\n",
              "      <td>03:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.148232</td>\n",
              "      <td>3.901993</td>\n",
              "      <td>49.501019</td>\n",
              "      <td>03:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.790505</td>\n",
              "      <td>4.043003</td>\n",
              "      <td>56.997253</td>\n",
              "      <td>03:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3iU15n38e+tjoQACSTREb1jDAIMNhhwA5e4xY4dx8EJMXaqE++6bfZdJ7ubbNZOnOZkE+JC4oLtxI4bxo2YalMEpndTBUgINdRQPe8fGhGFICFAM8+U3+e6dDHzzIzOfa5Bc88553nuY845REQk8kR5HYCIiHhDCUBEJEIpAYiIRCglABGRCKUEICISoZQAREQiVIzXAbRGly5dXGZmptdhiIiElLVr1x5zzqU193hIJIDMzEyys7O9DkNEJKSY2f6WHtcUkIhIhFICEBGJUEoAIiIRSglARCRCKQGIiEQoJQARkQilBCAiEoRKKmt4b0sux8qq/NaGEoCISBDafbSUe55by5bDx/3WhhKAiEgQKiyvASAlMdZvbSgBiIgEoaKKagBSEuP81oYSgIhIECoq9yWAJCUAEZGIUlRRQ2y0kRQX7bc2lABERIJQUXk1KYlxmJnf2lACEBEJQkUV1X6d/wclABGRoFRUUU1Kkv/OAAIlABGRoFRUUaMRgIhIJCquqPbrGUCgBCAiEnScc74RgKaAREQiyvETtdTVO00BiYhEmpMXgSkBiIhElpNlIHQWkIhIZAlEHSBQAhARCTpFJyuBKgGIiESUv08BKQGIiESUoopqoqOMDgkxfm1HCUBEJMg0XgPgz0JwoAQgIhJ0isqr6eTn+X9QAhARCTpFFdWkKgGIiESeovIaOvm5DAQoAYiIBJ1A7AUAfkwAZvaMmR01s81Njv2XmW00s/Vm9r6ZdfdX+yIioaihEJz/K4GCf0cA84AZpxx73Dk3yjk3Gngb+A8/ti8iEnLKq+uoqXN+rwQKfkwAzrmlQOEpx443uZsEOH+1LyISik4WggvACMC/Vxmchpn9CPgyUAJMa+F5c4A5AL179w5McCIiHgtUHSDwYBHYOfd951wv4AXgWy08b65zLss5l5WWlha4AEVEPFRU0VAHKNXPlUDB27OAXgBu9rB9EZGg0zgFFHYXgpnZwCZ3rwe2B7J9EZFgF8gpIL+tAZjZfGAq0MXMcoBHgavNbDBQD+wH7vVX+yIioaiovBoz6NjO/1NAfksAzrnbT3P4aX+1JyISDooqaujYLpboKP8WggNdCSwiElQKA1QHCJQARESCSnFFdUDqAIESgIhIUCksryE1ABeBgRKAiEhQaRgBKAGIiEScoopqjQBERCJNZXUdJ2rqtQYgIhJpAnkRGCgBiIgEjcJyJQARkYhU7CsEF4i9AEAJQEQkaBT6poC0CCwiEmGKKwJXCRSUAEREgkbhyVLQmgISEYkoxRU1JCfEEBsdmI9mJQARkSARyIvAQAlARCRoFJYHrgwEKAGIiASN4oqagJ0CCkoAIiJBo7A8cHsBgBKAiEjQCGQlUFACEBEJClW1dZRX15GapCkgEZGI0lgGQiMAEZEI03gRmE4DFRGJMEUVgb0KGJQARESCQlF5YyVQjQBERCJKYXkVAJ01BSQiElkKGjeDUQIQEYksheXVdGwXG7BCcODHBGBmz5jZUTPb3OTY42a23cw2mtlfzayTv9oXEQklBeXVAZ3+Af+OAOYBM0459gEwwjk3CtgJPOLH9kVEQkZhWWArgYIfE4BzbilQeMqx951ztb67K4Ge/mpfRCSUFJaHUQJoha8CCz1sX0QkaBSUV9G5fQQkADP7PlALvNDCc+aYWbaZZefn5wcuOBGRAKuvdxRV1IT/CMDM7gKuBe5wzrnmnuecm+ucy3LOZaWlpQUsPhGRQCuprKGu3tE5KT6g7cYEsjEzmwE8CFzqnKsIZNsiIsGq8RqAsJkCMrP5wCfAYDPLMbPZwJNAMvCBma03s9/5q30RkVDhRSE48OMIwDl3+2kOP+2v9kREQlVjGYiwXwMQEZF/dKzMNwUU4DUAJQAREY8VnqwDFLhS0KAEICLiucLyapITYoiPiQ5ou0oAIiIe86IOECgBiIh4rrC8KuALwKAEICLiuYKyalIDvAAMSgAiIp7TFJCISARyzlFUXk1qgK8CBiUAERFPHa+spbbeaQQgIhJpCho3g9cIQEQksvy9DpAWgUVEIsrJSqCaAhIRiSwFZd5UAgUlABERT3lVCRSUAEREPFVQXk37+BgSYgNbBwiUAEREPFVYXu3Jt39QAhAR8ZQSgIhIhCoo86YMBCgBiIh4qsCjSqCgBCAi4hnnHIXl1XRuH/iLwEAJQETEM6VVtdTUeVMHCJQAREQ8U+jhRWCgBCAi4pnGMhBelIIGJQAREc8UelgHCFqZAMwsycyifLcHmdnnzCzWv6GJiIS3gjLvykBA60cAS4EEM+sBvA/cCczzV1AiIpHg75VAg/ssIHPOVQA3Ab91zt0CDPdfWCIi4a+wvJrEuGjaxQW+DhCcRQIws4nAHcAC37EWIzazZ8zsqJltbnLsFjPbYmb1ZpZ1biGLiIQHL8tAQOsTwHeBR4C/Oue2mFk/4KMzvGYeMOOUY5tpGEUsPZsgRUTCUUG5d2UgAGJa8yTn3BJgCYBvMfiYc+47Z3jNUjPLPOXYNt/vOJdYRUTCSmF5FWkeXQUMrT8L6EUz62BmSTR8i99qZg/4MzAzm2Nm2WaWnZ+f78+mREQ8UVhW7clewI1aOwU0zDl3HLgBWAj0peFMIL9xzs11zmU557LS0tL82ZSISMA55zhWXk0Xjy4Cg9YngFjfef83AG8652oA57+wRETCW3l1HdW19SGxCPx7YB+QBCw1sz7AcX8F1ZZKKmu8DkFE5J94XQcIWpkAnHO/cs71cM5d7RrsB6a19Bozmw98Agw2sxwzm21mN5pZDjARWGBm7513D1rw6Bubue7Xy6mv12BFRIJLgW8z+M4eTgG16iwgM+sIPApM8R1aAvwnUNLca5xztzfz0F/PJsDzMaZPCn/8ZD8ff1bAJQO7BKpZEZEzaqwDFAqLwM8ApcCtvp/jwLP+CqqtXDW8KymJscxffcDrUERE/kGBx4XgoJUjAKC/c+7mJvd/aGbr/RFQW0qIjebmMT2Z9/E+8kurSEv2LtOKiDSVX+r9FFBrRwCVZnZJ4x0zuxio9E9Ibeu28b2prXe8ui7H61BERE46XFxJSmIsiXGt/R7e9lqbAO4FfmNm+8xsH/AkcI/fompDA9LbM75vKi+tPqDFYBEJGoeKK+mR0s7TGFp7FtAG59wFwChglHPuQmC6XyNrQ18c35t9BRWs3FPgdSgiIgAcKqqke8cQSACNnHPHfVcEA9zvh3j8YsaIrnRsF8uLWgwWkSDgnONwEIwAzmfyKWQqujUuBj+3ch8FZVV0PofiS8453lh/mJ++v4Oq2nrSk+NJT44nLTmemjpHfmlVw09ZFd07JXDjhT25fnR3unhY6ElEglNJZQ3l1XX06BRCI4BThNSE+u3je1FTd26LwTvzSrlt7kq++/J6UpPimD44nYwOCeSXVbF4Rz5r9hVSXl1Ln86JXDW8K4bxX29vZcKPFzF73hre25JLndYfRMTnUHHDOTReJ4AWRwBmVsrpP+gN8DbyszQwI5lxmSn86ZP9XNg7haw+KactS11X78g7foJDxZXkFFWw/kAxL6w6QFJ8DD++cSRfGNeL6KgzD3525pXy6rocXv/0EIueO0pm50RmT+7H58f09Gz3HxEJDoeKfAnA4ykgcy74v5lmZWW57Ozs8/49y3bl8/Xn11FWVcuA9PbcNq4Xlw3NYGdeKWv3F7F2fxGbckqorqs/+Zoog1vG9uKhmUPOqWZHbV09723JY+7Sz9iQU0JKYix3TszkK5MySfHwAhAR8c6zK/byw7e2kv3vl/t1mtjM1jrnmt19MaISAEB5VS0LNh5h/poDfHqg+OTxuOgoRvbsyJjencjskkTPlER6dGpHj07t2uQbu3OONfuKmLt0Dx9uyyMxLpo7L+rD7Ml9SU9OOO/fLyKh40cLtvLcyv1s+88Zft0g60wJwLsrEDySFB/DreN6ceu4XuzILWX13gKGduvAiB4dSYj139SMmTG+byrj+6ayI7eU3y7ezR+W7WHex/u4eWxPrhnZjfF9U4mNPp9lGREJBYeKK+neqZ3nuyNGXAJoanDXZAZ3Tfak3V/ediHfu3wQ/7f4M15dm8OLqw6QHB/DpYPTuGJYBlMHp9OxXWzAYxMR/ztUVOn5AjBEeALwWmaXJP7386N49HPDWL7rGIu2HWXR9qO8vfEIsdHGpP5dmDGiK1cMy9DppCJh5FDxCYZ26+B1GEoAwSAxLoYrh3flyuFdqa93rM8p5r0tuby7OZdHXtvEv/11E+MzU7lmVDdmjOiqNQOREHaipo5jZVV01whAThUVZYzpncKY3ik8PGMI23NLWbg5l3c2HeE/3tjCo29uYXxmKl+9pC9XDsvwfA5RRM7O4SC5BgCUAIKamTG0WweGduvA/VcMYmdeKQs2HuH19Ye457m1jO7ViQdnDGZSf212IxIqDhefALy/BgCUAELKoIxkBl2RzLenD+Ava3P45aJdfPEPq5g8sAt3TOjNxP5dtHAsEuQOFVcAGgHIOYqJjuK28b254cIePL9yP79d/Bn3Pr+OKIPRvTpxycA0rhvVjYEZgT/DSURadqj4BFEGXTt6v5anBBDCEmKj+drkfsyalMmnB4pZviufpbuO8eTfdvGrRbuYPiSduyf346J+qVorEAkSh4oqyeiQEBTX/CgBhIHY6KiTF5ndf+VgCsqqeH7lAf70yT5u/8NKRvXsyDenDdCisUgQOFRcERRnAMH5VQOVINW5fTz3XT6QFQ9P58c3jqT0RC33PLeWL8xdycac4jP/AhHxm8PFJ4Ji/h+UAMJaQmw0X5zQmw++N4Uf3TiCz46W8bknV/C9l9efPBVNRAKnvt5xpKRSIwAJnJjoKO6Y0IfFD0zlG1P7s2DTEab+dDE/fmcbxRXVXocnEjGOllZRU+eC4hRQUAKIKMkJsTw4Ywh/+5dLuW5Ud/6wbA+TH/uI33y0m4rqWq/DEwl7jRvB9NQIQLzSMyWRn916Ae/eN4UJfTvz+Hs7mPSTv/HwqxtZtiuf2ib7IYhI22lMAMEyBeS3s4DM7BngWuCoc26E71gq8DKQCewDbnXOFfkrBmnZ4K7JPDUri7X7C3l+5QHe3niEl9YcJDUpjsuHppPVJ5ULenViQHr7Vu2CJiItC5adwBr58zTQecCTwJ+aHHsYWOSc+4mZPey7/5AfY5BWGNsnlbF9UjlRU8eSnfks2HiEdzfn8kp2w/7JiXHRDO3WgaT4GOKio4iPiSIxLpqJ/Ttz2dAMXX0s0kqHiyvp2C6W9vHBcQa+36Jwzi01s8xTDl8PTPXd/iOwGCWAoJEQG81Vw7tyla8q6b6CctYfLGbDwWJ25JVSUllDdW091bV1FFXU8Oe1OcREGZMGdGHmiK5M6JtKZuckojRaEDmtxo1ggkWg01CGc+6I73YukBHg9qWVoqKMfmnt6ZfWnpvG9Pynx0+Wrd6cy0Jf2WqA5PgYhvfowKienbhsSDrj++oqZJFGh4oq6ZWa6HUYJ3k2DnHOOTNrdkNiM5sDzAHo3bt3wOKS1vmHstUzh7DraBnrDxSz8VAxm3JKmLdiH3OX7qFvlyRuyerJ58f0JL2D97VPRLx0uLiSi/qleh3GSYFOAHlm1s05d8TMugFHm3uic24uMBcaNoUPVIBy9sysoVJpRjK3jusFQEV1Le9syuWVNQd57N0d/Oz9nUwbnMYtWb2YPiQ9KOqgiARSSWUNpVW1QbMADIFPAG8Cs4Cf+P59I8DtS4AkxsXw+bE9+fzYnuzJL+OV7BxeW5fDh9uO0jkpjhsv7MEXxvVSxVKJGH/fCCYCpoDMbD4NC75dzCwHeJSGD/5XzGw2sB+41V/tS/Dol9aeh2cO4V+vHMTSXfn8OTuHP36yj6eW72VcZgpfnNCbmSO6kRAb7XWoIn7TeApo907BMxXqz7OAbm/mocv81aYEt5joKKYPyWD6kAwKyqp4dV0O81cf5Hsvb+CHb23lhtE9+Nzo7lzYq5MWjiXsNF4EFslTQCJAQ8XSOVP687VL+rFyTwEvrDrAi6sPMO/jffTo1I5rR3Xjugu6M7x7ByUDCQuf5ZcRFxNFl6R4r0M5SQlAPBXlu45g0oAuHD9Rwwdb8nhr42GeXr6X3y/dw4D09twwujvXj+4RVKfPiZyN0hM1/HXdIa4YmhFU18koAUjQ6JAQy81je3Lz2J4UlVfzzuYjvPHpYX76/k5++v5OxmWmMGtSJjOGdyVGZxFJCHl5zUFKq2qZM6Wf16H8AyUACUopSXHcMaEPd0zoQ05RBW+sP8wr2Qf51ouf0qNTO2ZN6sMXxvVWGQoJejV19TyzfC8T+jbU1gom+holQa9nSiLfnDaAv/3LVObeOZaeKe348Tvbmfg/i/j+XzexI7fU6xBFmvX2xsMcLjnBPZcG17d/0AhAQkh0lHHl8K5cObwrmw+V8OyKffx5bQ4vrDrA+L6p3HlRH2aM6KqLzCRoOOeYu3QvA9PbM3VQutfh/BP9pUhIGtGjIz+79QJWPXIZj8wcwpGSSr49/1OmPPYRv1vyGSUVNV6HKMLy3cfYduQ4d0/uF1SLv43MueCvspCVleWys7O9DkOCWF29Y/GOozy9fC8ff1ZAYlw0t4ztyV0X96VvlySvw5MIdefTq9iRW8qyh6YRHxP4Cx3NbK1zLqu5xzUFJGEhOsq4bGgGlw3NYMvhEp5Zvo8XVx/gTyv3M31wOl+9pC+T+nfWNQUSMFsPH2fZrmM8OGOwJx/+raEpIAk7w7s3TA+teHg6354+kPUHi7njqVXM+MUy3lh/iPr64B/1Suh7ZsVekuKiuWNCH69DaZYSgISt9OQE7r9iECsens5jnx8FwH0vree6J5ezZGc+oTD9KaHpRE0d727O5eqR3YL6VGUlAAl7CbHR3JrVi4X3TeYXXxjN8RM1zHpmNV/8wyo2HCz2OjwJQ0t35lNWVcu1F3T3OpQWKQFIxIiKMm64sAeL7p/KD64bxs68Uq7/zQq+/vxaPssv8zo8CSMLNh0hJTGWSf07ex1Ki5QAJOLExURx18V9WfLgNL57+UCW7sznyp8v5eFXN5JbcsLr8CTEnaip48OteSFxTUpwRyfiR+3jY/ju5YNY+uA0vjyxD6+tO8TlTyzhuZX7tVAs52zxjnzKq+u4ZmRwT/+AEoAIndvH8+h1w/nw/ksZ3asT/+/1zdw2dyV7NC0k5+DtjYdJTYoLqr1/m6MEIOLTu3Miz80ez2OfH8X23OPM/OUynvzbLiqqa70OTUJEZXUdi7YdZcaI0KhYG/wRigSQmXFrVi8+vP9Spg1O56fv72TKY4uZt2IvVbV1XocnQe6jHUeprKnj2pHdvA6lVZQARE4jvUMCv7tzLH++dyL905L4wVtbmfb4YuavPkB1bb3X4UmQWrDxCF3axzG+b/BP/4ASgEiLxmWm8tKci3h+9gTSOiTwyGubmPLYRzy1bI+mhuQfVFTXsmh7HjNHdAuJ6R9QAhA5IzPjkoFdeP0bk/jTV8fTp3Mi/71gG5N+8jd+tWgXldWaGhJYtO0oJ2rquWZUaEz/gBKASKuZGVMGpfHyPRN59euTyOqTwhMf7OTyJ5bwwdY8r8MTjy3YeIS05HjGZYbG9A8oAYick7F9Unhq1jhennMRSfHR3P2nbL72xzUcLKzwOjTxQHlVLR/tOMrMEV2JDsK6/81RAhA5DxP6dWbBdybzb1cP4ePPCrj8iSX8dvFuauq0UBxJPtpxlKraeq4OkbN/GikBiJyn2Ogo5kzpz6J/uZSpg9N47N0dXPfr5aw7UOR1aBIgCzfl0qV9XEhN/4ASgEib6daxHb+/M4u5d46lpLKGm//vY/799U0UV1R7HZr4UWV1HX/bfpSrhofW9A8oAYi0uSuHd+WD+y9l1sRMXlh1gMmPfcRvPtqts4XC1JKdDRd/XRNi0z/gUQIws/vMbLOZbTGz73oRg4g/tY+P4QefG87C+yYzoW8qj7+3g0sf/4jnV+7X+kCYeWdTLqlJoXPxV1MBTwBmNgK4GxgPXABca2YDAh2HSCAM6dqBp2aN48/3TqR3aiL//vpmZv5yGYt3HPU6NGkDJ2rqWLQtj6uGZ4TMxV9NeRHxUGCVc67COVcLLAFu8iAOkYAZl5nKn++dyNw7x1JbV89dz67hK8+u1kY0IW7pzobSzzNHhN70D3iTADYDk82ss5klAlcDvU59kpnNMbNsM8vOz88PeJAibc3MuHJ4V9773hT+7eohZO8r4qqfL+WHb23RQnGIWrg5l06JsUwM8p2/mhPwBOCc2wb8L/A+8C6wHvin1THn3FznXJZzListLS3AUYr4T3xMNHOm9OejB6ZyS1Yv/vjxPi59fDHPrtir9YEQUlXbsPPXlcMygn7nr+Z4ErVz7mnn3Fjn3BSgCNjpRRwiXurSPp7/uWkk79w3mZE9OvLDt7Zy1c+X8sHWPJzTjmTBbsXuY5RW1TIzBM/+aeTVWUDpvn970zD//6IXcYgEgyFdO/Dc7PE8c1cWGNz9p2y+MHclGw4Wex2atGDBxlw6JMRwcf8uXodyzmI8avdVM+sM1ADfdM7pf7pENDNj+pAMJg9M46U1B/nlhzu5/jcruHZUNx64ajB9Oid5HaI0UXqihve35HLViK7ExYTm9A94lACcc5O9aFck2MVGR3HnRX248cIezF3yGXOX7WHh5lxuGN2Db07rT7+09l6HKMD81Qcorapl1sRMr0M5L6GbukTCWPv4GO6/cjBLHpjGrImZLNh0mMufWMJ35n/KzrxSr8OLaNW19TyzfB+T+ndmZM+OXodzXpQARIJYRocE/uO6YSx7cDp3T+nHh9vyuOoXS/nWi+vYfVSJwAtvbjhM7vETzJnSz+tQzpuFwtkGWVlZLjs72+swRDxXVF7NU8v38OyKfVTW1HHdqO5857KBDEjX1FAgOOeY8YtlmMHC+yZjFtzF38xsrXMuq7nHNQIQCSEpSXE8cNUQlj80nXum9OeDrXlc8fMlfPOFdWw5XOJ1eGFv8c58duSVMmdKv6D/8G8Nr84CEpHzkJoUx8Mzh/C1yX15evlenvtkPws2HWH6kHS+NX0AY3qneB1iWJq7ZA/dOiZw3QXdvQ6lTWgEIBLCurSP56EZQ1jx0HT+5YpBfHqgiJt++zFfnbdGI4I2tjGnmE/2FPDVi/uG7JW/pwqPXohEuI6JsXz7soEsf2g6D80Ywtr9RVzzq+V8e/6n7D1W7nV4YeH3S/eQHB/DbeP/qXRZyFICEAkjSfExfH1qf5Y+OI1vTRvAh1vzuPyJJTzy2kaOlFR6HV7IWrDxCO9sOsKXJvYhOSHW63DajM4CEglj+aVV/Oaj3bywaj9mxpcv6sM3pg0gNSnO69BCxuq9hXzp6VVc0LMjz82eQEJstNchtdqZzgJSAhCJAAcLK/jFh7v466c5JMbFMGdKP742uS+JcToPpCW78kq5+f8+Ji05nle/PolOiaGVOHUaqIjQKzWRn916Ae99dwqT+nfmiQ92MvXxxcxffYBalaA+rbzjJ7jr2TXEx0Yz7yvjQ+7DvzWUAEQiyMCMZOZ+OYu/3DuRninteOS1Tcz45TJeyT5IRXWt1+EFjc2HSpj1zGqKKqp59q5x9EpN9Dokv9AUkEiEcs7x3pY8fvb+DnYdLaN9fAyfG92d28b1YmSPjmFxodPZ2nyohF8u2sUHW/PokBDDr784hksHhe6GVFoDEJEWOedYu7+I+asPsmDTYU7U1DO8ewe+dFEfrh/dPezXCZxzfLKngGdX7Dv5wf+1yf246+JMOoT4GT9KACLSasdP1PDG+sO8sHI/23NLSY6P4aYxPbjjoj4Mykj2Orw2daysir+szeGl1QfYV1BBx3axfPXivtx1cSYd24X2B38jJQAROWuNo4LnV+7nnU25VNfVM6Z3J24b35trR3ULyVHBsbIqsvcVsXZ/Idn7i9iUU0JtvWN8Ziq3T+jFzBHdQuoUz9ZQAhCR81JQVsVr6w4xf80B9uSXkxwfw9UjuzFjRFcmDehMfExwfWgWllezPfc4O3NL2Z1fxmdHy9mdX0Z+aRUAcdFRjOrZkfF9U7lpTA8GpIfXyKYpJQARaRPOOdbsK+KlNQd4f0seZVW1tI+PYdqQdGaO6Mq0wem0i/MmGbz+6SFe+/QQ248c56jvgx4gOSGGAent6Z/WnkEZ7RnbJ4URPToGXdLylzMlgNAbx4mIJ8yM8X1TGd83laraOj7eXcB7W3L5YGseb204TGJcNFcMy+C6Ud2ZPKhLQD5ka+vq+dE723h2xT76dUnikoFdGNq1A0O6JTM4I5m05PiIPJuptTQCEJHzUlfvWLW3gLc2HGHh5iMUV9SQnBDDVcO7cs2oblzcv4tfNk4vqazhWy+uY9muY3zl4ky+f/VQYsKkSmdb0RSQiARMTV09y3cf460Nh/lgax6lJ2rp2C6WGcO7cuOYHozPTCUq6vy/ke/KK+We59dysLCC/7p+BLeN790G0YcfTQGJSMDERkcxbXA60wanU1Vbx7Kdx1iw6QhvbzzMy9kH6dGpHTeN6cGNF/agX9rZbWN5qLiShZuO8PbGI6w/WExqUhzPz57AhH6d/dSb8KcRgIj4XWV1He9vzeXVdYdYviufegfDunVg5oiuzBzZ7bR7Gjvn2HL4OB9tP8qi7UdZf7AYgBE9OnD1yG7cPKYnGR0SAt2VkKIpIBEJKnnHT/DWhsMs3JzL2v1FAPRPS6Jbx3bExUQRHxNFlBnZ+wvJO16FGYzq2Ykrh2VwzchuZHZJ8rgHoUMJQESCVm7JCd7bksviHUcpqayhuq6eqpp6aurqGda9A9MGpzN1cDppyfFehxqStAYgIkGra8cEZk3KZNakTK9DiUg6Z0pEJEJ5kgDM7HtmtsXMNpvZfDPTSo6ISIAFPAGYWQ/gO0CWc24EEA3cFug4REQinbGP4hwAAAduSURBVFdTQDFAOzOLARKBwx7FISISsQKeAJxzh4CfAgeAI0CJc+79U59nZnPMLNvMsvPz8wMdpohI2PNiCigFuB7oC3QHkszsS6c+zzk31zmX5ZzLSksL3S3ZRESClRdTQJcDe51z+c65GuA1YJIHcYiIRDQvEsAB4CIzS7SGOq2XAds8iENEJKJ5ciWwmf0Q+AJQC3wKfM05V9XC8/OB/U0OdQRKWnm7C3DsPMJt+jvP9jmnO37qsZbuN95ueux8+nM+fWnusdbE39xtf/elpecFU19airM1z9H/M703zenjnGt+Dt05F3I/wNzW3gay26qts33O6Y6feqyl+0360PTYOffnfPpyLv3x53vTmr605Xuj/2eR+f8s3N6bU39C9Urgt87ydlu1dbbPOd3xU4+1dP+tZp5zrs6nL8091pr4W7p9rlr7O9rqvdH/s9YLp/9nrf09ofLe/IOQKAZ3Psws27VQDCnUhFN/1JfgFU79Cae+QNv2J1RHAGdjrtcBtLFw6o/6ErzCqT/h1Bdow/6E/QhAREROLxJGACIichpKACIiEUoJQEQkQkV0AjCzyWb2OzN7ysw+9jqe82FmUWb2IzP7tZnN8jqe82VmU81sme/9mep1POfLzJJ8xQ2v9TqW82VmQ33vy1/M7Otex3M+zOwGM/uDmb1sZld6Hc/5MLN+Zva0mf2lta8J2QRgZs+Y2VEz23zK8RlmtsPMdpvZwy39DufcMufcvcDbwB/9GW9L2qIvNBTY6wnUADn+irU12qg/DigDEvCwP23UF4CHgFf8E2XrtdHfzTbf382twMX+jLclbdSX151zdwP30lCdwBNt1Jc9zrnZZ9VwW11RFugfYAowBtjc5Fg08BnQD4gDNgDDgJE0fMg3/Ulv8rpXgORQ7gvwMHCP77V/CfX3BojyvS4DeCHE+3IFDZse3QVcG+rvje81nwMWAl8M9b74XvczYEyY9KXVf/8huym8c26pmWWecng8sNs5twfAzF4CrnfO/Q9w2qG3mfWmYU+CUj+G26K26IuZ5QDVvrt1/ov2zNrqvfEpAuL9EWdrtNF7MxVIouGPt9LM3nHO1fsz7ua01XvjnHsTeNPMFgAv+i/i5rXRe2PAT4CFzrl1/o24eW38N9NqIZsAmtEDONjkfg4w4QyvmQ0867eIzt3Z9uU14NdmNhlY6s/AztFZ9cfMbgKuAjoBT/o3tLN2Vn1xzn0fwMzuAo559eHfgrN9b6YCN9GQmN/xa2Rn72z/br5NQ4n6jmY2wDn3O38Gd5bO9n3pDPwIuNDMHvElihaFWwI4a865R72OoS045ypoSGZhwTn3Gg1JLWw45+Z5HUNbcM4tBhZ7HEabcM79CviV13G0BedcAQ1rGa0WsovAzTgE9Gpyv6fvWCgKp75AePUnnPoC4dUf9eUshFsCWAMMNLO+ZhZHw8Lbmx7HdK7CqS8QXv0Jp75AePVHfTkbXq16t8Gq+XwaNpVvPO1xtu/41cBOGlbPv+91nJHWl3DrTzj1Jdz6o76c/4+KwYmIRKhwmwISEZFWUgIQEYlQSgAiIhFKCUBEJEIpAYiIRCglABGRCKUEICHLzMoC3F6b7Bnh2+ugxMzWm9l2M/tpK15zg5kNa4v2RRopAYj4mFmLtbGcc5PasLllzrnRwIXAtWZ2prr6N9BQTVSkzSgBSFgxs/5m9q6ZrbWGHcWG+I5fZ2arzOxTM/vQzDJ8x39gZs+Z2QrgOd/9Z8xssZntMbPvNPndZb5/p/oe/4vvG/wLvrLCmNnVvmNrzexXZvZ2S/E65yqB9TRUfsTM7jazNWa2wcxeNbNEM5tEQ/39x32jhv7N9VPkbCgBSLiZC3zbOTcW+Ffgt77jy4GLnHMXAi8BDzZ5zTDgcufc7b77Q2goRT0eeNTMYk/TzoXAd32v7QdcbGYJwO+Bmb72084UrJmlAAP5ewnv15xz45xzFwDbaCgJ8DENNWAecM6Nds591kI/RVot4stBS/gws/bAJODPvi/k8PfNZHoCL5tZNxp2V9rb5KVv+r6JN1rgnKsCqszsKA27kp26LeVq51yOr931QCYNW1jucc41/u75wJxmwp1sZhto+PD/hXMu13d8hJn9Nw37ILQH3jvLfoq0mhKAhJMooNg3t36qXwNPOOfe9G1o8oMmj5Wf8tyqJrfrOP3fSWue05JlzrlrzawvsNLMXnHOrQfmATc45zb4NpCZeprXttRPkVbTFJCEDefccWCvmd0CDdv9mdkFvoc78vda6rP8FMIOoF+Trf3OuMm4b7TwExo2jQdIBo74pp3uaPLUUt9jZ+qnSKspAUgoSzSznCY/99PwoTnbN72yBbje99wf0DBlshY45o9gfNNI3wDe9bVTCpS04qW/A6b4Esf/A1YBK4DtTZ7zEvCAbxG7P833U6TVVA5apA2ZWXvnXJnvrKDfALuccz/3Oi6R09EIQKRt3e1bFN5Cw7TT7z2OR6RZGgGIiEQojQBERCKUEoCISIRSAhARiVBKACIiEUoJQEQkQikBiIhEqP8PSerN7D4n8k8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#구성하고 학습한 모델을 저장 , 모델 경로에 주의\n",
        "torch.save(model, f'/gdrive/My Drive/Colab Notebooks/corpus_data/model.pt')"
      ],
      "metadata": {
        "id": "JxsmtV0cxYFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning 된 모델 사용"
      ],
      "metadata": {
        "id": "r3Y6WoUnQ4rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"cuda version: {}\".format(torch.version.cuda))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNRKMfYEQrYu",
        "outputId": "87f3c783-2f9a-48fd-83ac-27ec5dc8e775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda version: 10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미 학습된 모델 및 KoGPT2 tokenizer 불러오기\n",
        "\n",
        "#=============================================================================\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>')\n",
        "model = torch.load('/gdrive/My Drive/Colab Notebooks/corpus_data/model.pt',map_location=torch.device('cpu'))\n",
        "#============================================================================="
      ],
      "metadata": {
        "id": "heOWhvNAydwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e647e7a-0041-400c-9035-6e1b52b7bc61"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make_line(키워드 혹은 가사 생성시 사용할 미끼가사 , 문장의 길이)\n",
        "#output = KoGPT2로 생성한 가사\n",
        "\n",
        "def make_line(rhyme_word,word_len):\n",
        "  prompt= rhyme_word\n",
        "  prompt_ids = tokenizer.encode(prompt)\n",
        "  inp = tensor(prompt_ids)[None]\n",
        "  preds = model.generate(inp,\n",
        "                           max_length=word_len,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           repetition_penalty=2.0,       \n",
        "                           use_cache=True\n",
        "                          ) \n",
        "  return tokenizer.decode(preds[0].cpu().numpy())"
      ],
      "metadata": {
        "id": "l5x_VfY6RVHK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_verse_seq(key_word,verse_maxlen,\n",
        "               max_rhyme_hit,min_rhyme_hit,min_level=0):\n",
        "  \n",
        "  base_sim = sim_after_rhyme(key_word,max_rhyme_hit,min_rhyme_hit,min_level)\n",
        "  base_sim = [[key_word]] + base_sim\n",
        "\n",
        "  use_word = []\n",
        "  verse = \"\"\n",
        "  verse_idx = 1\n",
        "\n",
        "  for i in base_sim:\n",
        "    if i[0] not in use_word:\n",
        "      ori_verse = verse\n",
        "      verse += (\" \" + i[0])\n",
        "      use_word.append(i[0])\n",
        "      print(\"now use_word... : \",use_word)\n",
        "      check = True\n",
        "\n",
        "      for p in range(len(verse)+1,verse_maxlen):\n",
        "        make = kss.split_sentences((make_line(verse,p)))\n",
        "        if len(make) > verse_idx:\n",
        "          verse = make_line(verse,p-1)\n",
        "          verse_idx += 1\n",
        "          check = False\n",
        "          break\n",
        "      \n",
        "      if check:\n",
        "        verse = ori_verse\n",
        "        use_word.pop(-1)\n",
        "\n",
        "  return verse\n",
        "\n"
      ],
      "metadata": {
        "id": "mknVifgqUXKU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_verse_not_seq(key_word,verse_maxlen,one_verse_len,\n",
        "               max_rhyme_hit,min_rhyme_hit,min_level=0):\n",
        "  \n",
        "  base_sim = sim_after_rhyme(key_word,max_rhyme_hit,min_rhyme_hit,min_level)\n",
        "  base_sim = [[key_word]] + base_sim\n",
        "  print(base_sim)\n",
        "\n",
        "  use_word = []\n",
        "  check = 0\n",
        "  ori_verse =\"\"\n",
        "\n",
        "  for i in base_sim:\n",
        "    if i[0] not in use_word:\n",
        "      verse = i[0] + \" \"\n",
        "      use_word.append(i[0])\n",
        "      print(\"now use_words... : \",use_word)\n",
        "      check += 1\n",
        "\n",
        "      for p in range(len(verse)+1,one_verse_len):\n",
        "        make = kss.split_sentences((make_line(verse,p)))\n",
        "        if len(make) >= 2:\n",
        "          parsing_verse = make_line(verse,p-1)\n",
        "          ori_verse += (\" \" + parsing_verse)\n",
        "          print(parsing_verse)\n",
        "          break\n",
        "      \n",
        "      if check >= verse_maxlen:\n",
        "        break\n",
        "\n",
        "  print(ori_verse)\n",
        "  return ori_verse"
      ],
      "metadata": {
        "id": "gfYimsoXkHGo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_verse_choose(key_word,verse_maxlen,one_verse_max_len,\n",
        "               max_rhyme_hit,min_rhyme_hit,min_level=0):\n",
        "  \n",
        "  base_sim = sim_after_rhyme(key_word,max_rhyme_hit,min_rhyme_hit,min_level)\n",
        "  base_sim = [[key_word]] + base_sim\n",
        "\n",
        "  use_word = []\n",
        "  check = 0\n",
        "  ori_verse = []\n",
        "\n",
        "  for i in base_sim:\n",
        "    if i[0] not in use_word:\n",
        "      verse = i[0] + \" \"\n",
        "      use_word.append(i[0])\n",
        "      print(\"now using_words... : \",use_word)\n",
        "\n",
        "      for p in range(len(verse)+1,one_verse_max_len):\n",
        "        make = kss.split_sentences((make_line(verse,p)))\n",
        "        if len(make) >= 2 or p == one_verse_max_len-1:\n",
        "          parsing_verse = make_line(verse,p-1)\n",
        "\n",
        "          parsing_list = list(parsing_verse.split(\" \"))\n",
        "          parsing_len = len(parsing_list)\n",
        "          print(\"========================\")\n",
        "          print(\"현재가사 : \")\n",
        "          for gasa in ori_verse:\n",
        "            print(gasa)\n",
        "          print(\"========================\")\n",
        "          print(\"가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\")\n",
        "          print(\"========================\")\n",
        "          for k in range(1,parsing_len+1):\n",
        "            result = ' '.join(s for s in parsing_list[0:k])\n",
        "            stdout.write(\"선택 %d : %s \\n\" % (k,result))\n",
        "          print(\"========================\")\n",
        "          cho = int(input())\n",
        "          if cho != -1:\n",
        "            ori_verse.append(' '.join(s for s in parsing_list[0:cho]))\n",
        "            stdout.flush()\n",
        "            check += 1\n",
        "          break\n",
        "      \n",
        "      if check >= verse_maxlen:\n",
        "        break\n",
        "\n",
        "  return ori_verse"
      ],
      "metadata": {
        "id": "rseKLJdJqJnW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_verse_choose_without_word2vec(\n",
        "    key_word,verse_maxlen,one_verse_max_len,\n",
        "    max_rhyme_hit,min_rhyme_hit,min_level=0):\n",
        "  \n",
        "  a,b,c = score_rank(key_word,max_rhyme_hit,min_rhyme_hit)\n",
        "  base_sim =  a + b + c\n",
        "  base_sim.sort(key=lambda x : x[1],reverse=True)\n",
        "  base_sim = [[key_word]] + base_sim\n",
        "\n",
        "  use_word = []\n",
        "  check = 0\n",
        "  ori_verse = []\n",
        "\n",
        "  for i in base_sim:\n",
        "    if i[0] not in use_word:\n",
        "      verse = i[0] + \" \"\n",
        "      use_word.append(i[0])\n",
        "      print(\"now using_words... : \",use_word)\n",
        "\n",
        "      for p in range(len(verse)+1,one_verse_max_len):\n",
        "        make = kss.split_sentences((make_line(verse,p)))\n",
        "        if len(make) >= 2 or p == one_verse_max_len-1:\n",
        "          parsing_verse = make_line(verse,p-1)\n",
        "\n",
        "          parsing_list = list(parsing_verse.split(\" \"))\n",
        "          parsing_len = len(parsing_list)\n",
        "          print(\"========================\")\n",
        "          print(\"현재가사 : \")\n",
        "          for gasa in ori_verse:\n",
        "            print(gasa)\n",
        "          print(\"========================\")\n",
        "          print(\"가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\")\n",
        "          print(\"========================\")\n",
        "          for k in range(1,parsing_len+1):\n",
        "            result = ' '.join(s for s in parsing_list[0:k])\n",
        "            stdout.write(\"선택 %d : %s \\n\" % (k,result))\n",
        "          print(\"========================\")\n",
        "          cho = int(input())\n",
        "          if cho != -1:\n",
        "            ori_verse.append(' '.join(s for s in parsing_list[0:cho]))\n",
        "            stdout.flush()\n",
        "            check += 1\n",
        "          break\n",
        "      \n",
        "      if check >= verse_maxlen:\n",
        "        break\n",
        "\n",
        "  return ori_verse"
      ],
      "metadata": {
        "id": "__pro1PX4K5E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=============================================================================\n",
        "#모든 쉘 실행 후 Colab or jupyter notebook 상에서 사용\n",
        "#=============================================================================\n",
        "\n",
        "#함수 설명\n",
        "\n",
        "#make_line(rhyme_word,word_len)\n",
        "  #rhyme_word : 키워드 혹은 가사 생성시 사용할 미끼가사\n",
        "  #word_len : 전체 가사의 길이\n",
        "\n",
        "  #output : 라임을 고려하지 않은 일반적인 가사\n",
        "\n",
        "#make_verse_seq(key_word,verse_maxlen,\n",
        "               #max_rhyme_hit,min_rhyme_hit,min_level=0)\n",
        "  #key_word : 가사에 처음으로 사용할 단어\n",
        "  #verse_maxlen : 전체 가사의 길이\n",
        "  #max_rhyme_hit : 사용할 단어들의 최대 라임 HIT\n",
        "  #min_rhyme_hit : 사용할 단어들의 최소 라임 HIT\n",
        "  #min_level=0 : 사용할 단어들의 word2vec 최소 유사도 ( 미만이면 사용 X )\n",
        "\n",
        "  #시퀀스로 가사를 생성하는 방식\n",
        "  #한단어로 가사를 만들고 그 위에 덮어 씌우는 방식\n",
        "\n",
        "#make_verse_not_seq(key_word,verse_maxlen,one_verse_len,\n",
        "               #max_rhyme_hit,min_rhyme_hit,min_level=0)\n",
        "  #key_word : 가사에 처음으로 사용할 단어\n",
        "  #verse_maxlen : 전체 가사의 줄의 개수\n",
        "  #one_verse_len : 허용할 가사 한줄의 최대 길이\n",
        "  #max_rhyme_hit : 사용할 단어들의 최대 라임 HIT\n",
        "  #min_rhyme_hit : 사용할 단어들의 최소 라임 HIT\n",
        "  #min_level=0 : 사용할 단어들의 word2vec 최소 유사도 ( 미만이면 사용 X )\n",
        "\n",
        "  #여러 단어들을 통해 가사를 각각 한 줄씩 만들고\n",
        "  #이후 합치는 방법으로 진행\n",
        "\n",
        "# make_verse_choose_without_word2vec(\n",
        "    #key_word,verse_maxlen,one_verse_max_len,\n",
        "    #max_rhyme_hit,min_rhyme_hit,min_level=0)\n",
        "\n",
        "  #key_word : 가사에 처음으로 사용할 단어\n",
        "  #verse_maxlen : 전체 가사의 줄의 개수\n",
        "  #one_verse_len : 허용할 가사 한줄의 최대 길이\n",
        "  #max_rhyme_hit : 사용할 단어들의 최대 라임 HIT\n",
        "  #min_rhyme_hit : 사용할 단어들의 최소 라임 HIT\n",
        "  #min_level=0 : 사용할 단어들의 word2vec 최소 유사도 ( 미만이면 사용 X )\n",
        "\n",
        "  #가사 생성은 모델이 진행하지만 , 선택은 사람이 할 수 있음\n",
        "  #인공지능이 생성한 여러가지 가사들 중 사용자가 원하는 가사를 선택\n",
        "  #한줄 한줄 이어나가 최종적인 가사 전체를 구성\n",
        "\n",
        "#============================================================================="
      ],
      "metadata": {
        "id": "1j1HOn5czcqZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyc = make_verse_choose(\"여름\",5,100,5,4)\n",
        "for i in kss.split_sentences(lyc):\n",
        "  #문장 단위로 나누어 확인\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "nTOH3lp0MHOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131af975-c459-4309-b2e2-94c91fb69580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "now using_words... :  ['여름']\n",
            "========================\n",
            "현재가사 : \n",
            "========================\n",
            "가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\n",
            "========================\n",
            "선택 1 : 여름 \n",
            "선택 2 : 여름 heart \n",
            "선택 3 : 여름 heart break \n",
            "선택 4 : 여름 heart break my \n",
            "선택 5 : 여름 heart break my skill \n",
            "선택 6 : 여름 heart break my skill you \n",
            "선택 7 : 여름 heart break my skill you feel \n",
            "선택 8 : 여름 heart break my skill you feel the \n",
            "선택 9 : 여름 heart break my skill you feel the voice \n",
            "선택 10 : 여름 heart break my skill you feel the voice coffe, \n",
            "선택 11 : 여름 heart break my skill you feel the voice coffe, likes \n",
            "선택 12 : 여름 heart break my skill you feel the voice coffe, likes girls \n",
            "선택 13 : 여름 heart break my skill you feel the voice coffe, likes girls Dance \n",
            "선택 14 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with \n",
            "선택 15 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a \n",
            "선택 16 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond \n",
            "선택 17 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what \n",
            "선택 18 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im \n",
            "선택 19 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not \n",
            "선택 20 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone \n",
            "선택 21 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All \n",
            "선택 22 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only \n",
            "선택 23 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing \n",
            "선택 24 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as \n",
            "선택 25 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your \n",
            "선택 26 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever \n",
            "선택 27 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and \n",
            "선택 28 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own \n",
            "선택 29 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three \n",
            "선택 30 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard \n",
            "선택 31 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to \n",
            "선택 32 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay \n",
            "선택 33 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack \n",
            "선택 34 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here \n",
            "선택 35 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in \n",
            "선택 36 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition \n",
            "선택 37 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever \n",
            "선택 38 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget \n",
            "선택 39 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget Turn \n",
            "선택 40 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget Turn around \n",
            "선택 41 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget Turn around high \n",
            "선택 42 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget Turn around high Light \n",
            "선택 43 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget Turn around high Light from \n",
            "선택 44 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget Turn around high Light from reallin \n",
            "선택 45 : 여름 heart break my skill you feel the voice coffe, likes girls Dance with a diamond what Im not alone All only thing as Your ever and own Three Heard to stay attack Here in amazition Whenever forget Turn around high Light from reallin 무너져 \n",
            "========================\n",
            " 3\n",
            "now using_words... :  ['여름', '보름']\n",
            "========================\n",
            "현재가사 : \n",
            "여름 heart break\n",
            "========================\n",
            "가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\n",
            "========================\n",
            "선택 1 : 보름 \n",
            "선택 2 : 보름 켠의 \n",
            "선택 3 : 보름 켠의 인형 \n",
            "선택 4 : 보름 켠의 인형 가만히 \n",
            "선택 5 : 보름 켠의 인형 가만히 눈을 \n",
            "선택 6 : 보름 켠의 인형 가만히 눈을 감았어 \n",
            "========================\n",
            "6\n",
            "now using_words... :  ['여름', '보름', '보름달']\n",
            "========================\n",
            "현재가사 : \n",
            "여름 heart break\n",
            "보름 켠의 인형 가만히 눈을 감았어\n",
            "========================\n",
            "가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\n",
            "========================\n",
            "선택 1 : 보름달 \n",
            "선택 2 : 보름달 넌 \n",
            "선택 3 : 보름달 넌 내맘을 \n",
            "선택 4 : 보름달 넌 내맘을 몰라주니 \n",
            "선택 5 : 보름달 넌 내맘을 몰라주니 무심하게 \n",
            "선택 6 : 보름달 넌 내맘을 몰라주니 무심하게 말하지마 \n",
            "선택 7 : 보름달 넌 내맘을 몰라주니 무심하게 말하지마 니가 \n",
            "선택 8 : 보름달 넌 내맘을 몰라주니 무심하게 말하지마 니가 날 \n",
            "선택 9 : 보름달 넌 내맘을 몰라주니 무심하게 말하지마 니가 날 좋아한다면 \n",
            "선택 10 : 보름달 넌 내맘을 몰라주니 무심하게 말하지마 니가 날 좋아한다면 그래야되잖아 \n",
            "========================\n",
            "4\n",
            "now using_words... :  ['여름', '보름', '보름달', '얼음']\n",
            "========================\n",
            "현재가사 : \n",
            "여름 heart break\n",
            "보름 켠의 인형 가만히 눈을 감았어\n",
            "보름달 넌 내맘을 몰라주니\n",
            "========================\n",
            "가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\n",
            "========================\n",
            "선택 1 : 얼음 \n",
            "선택 2 : 얼음 팡 \n",
            "선택 3 : 얼음 팡 하고 \n",
            "선택 4 : 얼음 팡 하고 터질 \n",
            "선택 5 : 얼음 팡 하고 터질 것 \n",
            "선택 6 : 얼음 팡 하고 터질 것 같아 \n",
            "선택 7 : 얼음 팡 하고 터질 것 같아 어떡해 \n",
            "선택 8 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 \n",
            "선택 9 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 \n",
            "선택 10 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 \n",
            "선택 11 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 \n",
            "선택 12 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 \n",
            "선택 13 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 \n",
            "선택 14 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 \n",
            "선택 15 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 \n",
            "선택 16 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 \n",
            "선택 17 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 \n",
            "선택 18 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 \n",
            "선택 19 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why \n",
            "선택 20 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre \n",
            "선택 21 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine \n",
            "선택 22 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze \n",
            "선택 23 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, \n",
            "선택 24 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling \n",
            "선택 25 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to \n",
            "선택 26 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to say \n",
            "선택 27 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to say goodbye \n",
            "선택 28 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to say goodbye 이리와봐요 \n",
            "선택 29 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to say goodbye 이리와봐요 왜 \n",
            "선택 30 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to say goodbye 이리와봐요 왜 이래야 \n",
            "선택 31 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to say goodbye 이리와봐요 왜 이래야 하는지 \n",
            "선택 32 : 얼음 팡 하고 터질 것 같아 어떡해 자꾸만 너에게 다가서는 그만큼 매일 나에게 고백하는 널 향한 내 맘은 why youre mine craze baby, telling to say goodbye 이리와봐요 왜 이래야 하는지 몰라줘 \n",
            "========================\n",
            "7\n",
            "now using_words... :  ['여름', '보름', '보름달', '얼음', '결승']\n",
            "========================\n",
            "현재가사 : \n",
            "여름 heart break\n",
            "보름 켠의 인형 가만히 눈을 감았어\n",
            "보름달 넌 내맘을 몰라주니\n",
            "얼음 팡 하고 터질 것 같아 어떡해\n",
            "========================\n",
            "가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\n",
            "========================\n",
            "선택 1 : 결승 \n",
            "선택 2 : 결승 넌 \n",
            "선택 3 : 결승 넌 내 \n",
            "선택 4 : 결승 넌 내 손바닥 \n",
            "선택 5 : 결승 넌 내 손바닥 안돼 \n",
            "========================\n",
            "4\n",
            "now using_words... :  ['여름', '보름', '보름달', '얼음', '결승', '구름']\n",
            "========================\n",
            "현재가사 : \n",
            "여름 heart break\n",
            "보름 켠의 인형 가만히 눈을 감았어\n",
            "보름달 넌 내맘을 몰라주니\n",
            "얼음 팡 하고 터질 것 같아 어떡해\n",
            "결승 넌 내 손바닥\n",
            "========================\n",
            "가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\n",
            "========================\n",
            "선택 1 : 구름 \n",
            "선택 2 : 구름 팡 \n",
            "선택 3 : 구름 팡 하고 \n",
            "선택 4 : 구름 팡 하고 터질 \n",
            "선택 5 : 구름 팡 하고 터질 것 \n",
            "선택 6 : 구름 팡 하고 터질 것 같아 \n",
            "선택 7 : 구름 팡 하고 터질 것 같아 어머어쩜 \n",
            "선택 8 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 \n",
            "선택 9 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 \n",
            "선택 10 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 \n",
            "선택 11 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 \n",
            "선택 12 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 \n",
            "선택 13 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 \n",
            "선택 14 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 \n",
            "선택 15 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 설레이는 \n",
            "선택 16 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 설레이는 건지 \n",
            "선택 17 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 설레이는 건지 아님 \n",
            "선택 18 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 설레이는 건지 아님 안 \n",
            "선택 19 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 설레이는 건지 아님 안 되겠니 \n",
            "선택 20 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 설레이는 건지 아님 안 되겠니 우린 \n",
            "선택 21 : 구름 팡 하고 터질 것 같아 어머어쩜 좋아 자꾸자꾸 그럼 나 뿔나니까 내 맘이 설레이는 건지 아님 안 되겠니 우린 친구잖아 \n",
            "========================\n",
            "6\n",
            "now using_words... :  ['여름', '보름', '보름달', '얼음', '결승', '구름', '열흘']\n",
            "========================\n",
            "현재가사 : \n",
            "여름 heart break\n",
            "보름 켠의 인형 가만히 눈을 감았어\n",
            "보름달 넌 내맘을 몰라주니\n",
            "얼음 팡 하고 터질 것 같아 어떡해\n",
            "결승 넌 내 손바닥\n",
            "구름 팡 하고 터질 것 같아\n",
            "========================\n",
            "가장 적절한 가사 번호 선택, 마음에 들지 않으면 -1로 스킵\n",
            "========================\n",
            "선택 1 : 열흘 \n",
            "선택 2 : 열흘 째깍 \n",
            "선택 3 : 열흘 째깍 시간이 \n",
            "선택 4 : 열흘 째깍 시간이 흘러가네 \n",
            "========================\n"
          ]
        }
      ]
    }
  ]
}